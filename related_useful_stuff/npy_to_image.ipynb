{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80991512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pprint import pformat\n",
    "\n",
    "\n",
    "# custom dependencies\n",
    "def askDIR(query_title: str = \"Please select a directory\"):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.call(\"wm\", \"attributes\", \".\", \"-topmost\", True)\n",
    "    DIR_path = filedialog.askdirectory(title=query_title)\n",
    "    return DIR_path\n",
    "\n",
    "\n",
    "def askFILES(query_title: str = \"Please select a number of files\"):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.call(\"wm\", \"attributes\", \".\", \"-topmost\", True)\n",
    "    FILE_path = filedialog.askopenfilenames(title=query_title)\n",
    "    return FILE_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Name: mic_val\n",
      "Set Name: NanTex SRM Dataset — STED 1 (Leica Infinity Line)\n",
      "Files: (2497, 2497) | dtype: uint8 | number files: 2\n",
      "Output Path: Z:/NanTex/dump/converted\\NanTex SRM Dataset — STED 1 (Leica Infinity Line)\\mic_val\n",
      "Has Files: False\n"
     ]
    }
   ],
   "source": [
    "## DISCLAIMER:\n",
    "## ASSUMING A FILE STRUCTURE LIKE /../../../Wurzburg/ER_train/*.npy\"\n",
    "## CHANGE THE COMMENTED LINES IF NECESSARY\n",
    "\n",
    "# get files from directory\n",
    "file_paths = askFILES()\n",
    "dir_name = os.path.dirname(file_paths[0]).split(\"/\")[-1]  ## CHANGE IF NECESSARY\n",
    "set_name = os.path.dirname(file_paths[0]).split(\"/\")[-2]  ## CHANGE IF NECESSARY\n",
    "files = {f\"{dir_name}_{i}\": np.load(f) for i, f in enumerate(file_paths)}\n",
    "\n",
    "# overview\n",
    "print(\"Directory Name:\", dir_name)\n",
    "print(\"Set Name:\", set_name)\n",
    "print(\n",
    "    \"Files:\",\n",
    "    files[list(files.keys())[0]].shape,\n",
    "    \"| dtype:\",\n",
    "    files[list(files.keys())[0]].dtype,\n",
    "    \"| number files:\",\n",
    "    len(files),\n",
    ")\n",
    "\n",
    "# file out direction\n",
    "out_path = \"Z:/NanTex/dump/converted\"\n",
    "out_path = os.path.join(out_path, set_name, dir_name)\n",
    "\n",
    "# create dir\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# overview\n",
    "print(\"Output Path:\", out_path)\n",
    "print(\"Has Files:\", bool(len(os.listdir(out_path))))\n",
    "if os.listdir(out_path):\n",
    "    sys.exit(\"Output directory is not empty, exiting to prevent overwriting...\")\n",
    "\n",
    "## convert to images\n",
    "for file_name, image_array in files.items():\n",
    "    # iterate over files and turn them into monochromatic pngs\n",
    "    image = Image.fromarray(image_array)\n",
    "    image = image.convert(\"L\")  # Convert to monochromatic\n",
    "    image.save(os.path.join(out_path, f\"{file_name}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) ER_test': 20,\n",
      " 'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) ER_train': 19,\n",
      " 'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) ER_val': 6,\n",
      " 'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) Lyso_test': 20,\n",
      " 'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) Lyso_train': 19,\n",
      " 'NanTex SRM Dataset — Airyscan (Zeiss LSM 880) Lyso_val': 6,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) CLA_test': 5,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) CLA_train': 14,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) CLA_val': 5,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) MT_test': 5,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) MT_train': 14,\n",
      " 'NanTex SRM Dataset — SIM (ZEISS Elyra 7 lattice SIM) MT_val': 6,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) ACT_test': 1,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) ACT_train': 3,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) ACT_val': 1,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) LNP_test': 2,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) LNP_train': 4,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) LNP_val': 1,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) MIC_test': 4,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) MIC_train': 13,\n",
      " 'NanTex SRM Dataset — SMLM I (ShareLoc) MIC_val': 2,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) CLA_test': 2,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) CLA_train': 6,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) CLA_val': 1,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) ER_test': 3,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) ER_train': 4,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) ER_val': 1,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) MIC_test': 5,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) MIC_train': 8,\n",
      " 'NanTex SRM Dataset — SMLM II (Olympus IX-71 dSTORM) MIC_val': 1,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) clath_test': 2,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) clath_train': 10,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) clath_val': 2,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) mic_test': 2,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) mic_train': 10,\n",
      " 'NanTex SRM Dataset — STED 1 (Leica Infinity Line) mic_val': 2,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) mito_test': 2,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) mito_val': 4,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) mitro_train': 11,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) perox_test': 2,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) perox_train': 11,\n",
      " 'NanTex SRM Dataset — STED 2 (Abberior STEDYCON) perox_val': 4}\n"
     ]
    }
   ],
   "source": [
    "## FILE COUNTING\n",
    "\n",
    "root: str = askDIR()  ## ADD YOUR ROOT PATH, e.g. \"N:/ZENODO_DUMP\"\n",
    "filetype: str = \"png\"\n",
    "\n",
    "# crawl root recursively and get the number of files in each directory\n",
    "files: dict = {}\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    files[dirpath] = [f for f in filenames if f.endswith(f\".{filetype}\")]\n",
    "\n",
    "## get file counts\n",
    "file_counts: dict = {\n",
    "    k.split(root + os.path.sep)[-1].replace(\"\\\\\", \" \"): len(v)\n",
    "    for k, v in files.items()\n",
    "    if not len(v) == 0\n",
    "}\n",
    "pprint(file_counts, compact=True, sort_dicts=True)\n",
    "\n",
    "# save as txt\n",
    "with open(os.path.join(root, f\"file_counts_{filetype}.txt\"), \"w\") as f:\n",
    "    f.write(pformat(file_counts, compact=True, sort_dicts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clath_test': 2,\n",
      " 'clath_train': 10,\n",
      " 'clath_val': 2,\n",
      " 'mic_test': 2,\n",
      " 'mic_train': 10,\n",
      " 'mic_val': 2}\n"
     ]
    }
   ],
   "source": [
    "## FILE COUNTING\n",
    "\n",
    "root: str = askDIR()  ## ADD YOUR ROOT PATH, e.g. \"N:/ZENODO_DUMP\"\n",
    "filetype: str = \"npy\"\n",
    "\n",
    "# crawl root recursively and get the number of files in each directory\n",
    "files: dict = {}\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    files[dirpath] = [f for f in filenames if f.endswith(f\".{filetype}\")]\n",
    "\n",
    "## get file counts\n",
    "file_counts: dict = {\n",
    "    k.split(root + os.path.sep)[-1].replace(\"\\\\\", \" \"): len(v)\n",
    "    for k, v in files.items()\n",
    "    if not len(v) == 0\n",
    "}\n",
    "pprint(file_counts, compact=True, sort_dicts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d00a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
