{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "# Model\n",
    "from NanTex_backend.deep_learning.dl_building_blocks import *\n",
    "from NanTex_backend.deep_learning.dl_model_assembly import (\n",
    "    assembled_model,\n",
    "    hyperparameters,\n",
    ")\n",
    "\n",
    "# Dataloaders\n",
    "from NanTex_backend.batching.BatchDataLoader import BatchDataLoader_Handler\n",
    "from NanTex_backend.data_preparation import img_augmentation as img_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup image augmentation\n",
    "train_augmentation_pipeline = img_augmentation.train_augmentation_pipeline\n",
    "val_augmentation_pipeline = img_augmentation.val_augmentation_pipeline\n",
    "\n",
    "## Setup BatchDataLoader\n",
    "BDL: BatchDataLoader_Handler\n",
    "BDL = BatchDataLoader_Handler.from_config(\n",
    "    config_file_path=\"./configs/BatchDataLoader_wurzburg_config.json\", DEBUG=False\n",
    ")\n",
    "\n",
    "BDL.setup_augmentation_pipelines(\n",
    "    raw_aug=train_augmentation_pipeline, val_aug=val_augmentation_pipeline\n",
    ")\n",
    "\n",
    "train_gen, val_gen = BDL.build_BatchDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if CUDA is available\n",
    "import torch\n",
    "\n",
    "# set backend flags\n",
    "torch.backends.cudnn.enabled = True  # use CUDNN Cuda Deep Neural Network library\n",
    "torch.backends.cudnn.benchmark = True  # enable benchmarking for optimized performance -> benchmark multiple convolution algorithms and choose the fastest\n",
    "\n",
    "print(\"Checking CUDA availability...\")\n",
    "print(\"  version:\", torch.__version__)\n",
    "print(\"  CUDA available:\", torch.cuda.is_available())\n",
    "print(\"  cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print()\n",
    "print(\"Checking on GPU...\")\n",
    "print(\"  GPU count:\", torch.cuda.device_count())\n",
    "print(\"  Current device:\", torch.cuda.current_device())\n",
    "print(\"  Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print()\n",
    "print(\"cuDNN properties:\")\n",
    "print(\"  Version:\", torch.backends.cudnn.version())\n",
    "print(\"  Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"  Benchmark:\", torch.backends.cudnn.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparams\n",
    "# hyperparameters.update({\"save_dir\":f\"{pyD.askDIR()}\"})\n",
    "hyperparameters.update({\"save_dir\": \"Z:\\\\NanTex\\\\models_regeneration\\\\wurzburg_aug25\"})\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assembled model\n",
    "list(assembled_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NanTex_backend.Util.pyDialogue import pyDialogue as pyD\n",
    "\n",
    "## get weights\n",
    "assembled_model[\"model\"].load_state_dict(torch.load(pyD.askFILE(), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Setup Test\n",
    "try:\n",
    "    train(\n",
    "        train_loader=train_gen,\n",
    "        val_loader=val_gen,\n",
    "        net=assembled_model[\"model\"],\n",
    "        activation=assembled_model[\"activation\"],\n",
    "        optimizer=assembled_model[\"optimizer\"],\n",
    "        loss_fn=assembled_model[\"loss_fn\"],\n",
    "        device=assembled_model[\"device\"],\n",
    "        epochs=hyperparameters[\"epochs\"],\n",
    "        steps_per_epoch=hyperparameters[\"steps_per_epoch\"],\n",
    "        val_per_epoch=hyperparameters[\"val_per_epoch\"],\n",
    "        save_dir=hyperparameters[\"save_dir\"],\n",
    "        write_val_per_feature=True,\n",
    "        data_range=1,\n",
    "        uses_11_normalization=False,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\")\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autobatch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup image augmentation\n",
    "train_augmentation_pipeline = img_augmentation.train_augmentation_pipeline\n",
    "val_augmentation_pipeline = img_augmentation.val_augmentation_pipeline\n",
    "\n",
    "## Setup BatchDataLoader\n",
    "BDL: BatchDataLoader_Handler\n",
    "BDL = BatchDataLoader_Handler.from_config(\n",
    "    config_file_path=\"./configs/BatchDataLoader_wurzburg_autobatch_config.json\",\n",
    "    DEBUG=False,\n",
    ")\n",
    "\n",
    "BDL.setup_augmentation_pipelines(\n",
    "    raw_aug=train_augmentation_pipeline, val_aug=val_augmentation_pipeline\n",
    ")\n",
    "\n",
    "train_gen, val_gen = BDL.build_BatchDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if CUDA is available\n",
    "import torch\n",
    "\n",
    "# set backend flags\n",
    "torch.backends.cudnn.enabled = True  # use CUDNN Cuda Deep Neural Network library\n",
    "torch.backends.cudnn.benchmark = True  # enable benchmarking for optimized performance -> benchmark multiple convolution algorithms and choose the fastest\n",
    "\n",
    "print(\"Checking CUDA availability...\")\n",
    "print(\"  version:\", torch.__version__)\n",
    "print(\"  CUDA available:\", torch.cuda.is_available())\n",
    "print(\"  cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print()\n",
    "print(\"Checking on GPU...\")\n",
    "print(\"  GPU count:\", torch.cuda.device_count())\n",
    "print(\"  Current device:\", torch.cuda.current_device())\n",
    "print(\"  Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print()\n",
    "print(\"cuDNN properties:\")\n",
    "print(\"  Version:\", torch.backends.cudnn.version())\n",
    "print(\"  Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"  Benchmark:\", torch.backends.cudnn.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparams\n",
    "# hyperparameters.update({\"save_dir\":f\"{pyD.askDIR()}\"})\n",
    "hyperparameters.update({\"save_dir\": \"Z:\\\\NanTex\\\\models_regeneration\\\\wurzburg_aug25\"})\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Setup Test\n",
    "try:\n",
    "    train(\n",
    "        train_loader=train_gen,\n",
    "        val_loader=val_gen,\n",
    "        net=assembled_model[\"model\"],\n",
    "        activation=assembled_model[\"activation\"],\n",
    "        optimizer=assembled_model[\"optimizer\"],\n",
    "        loss_fn=assembled_model[\"loss_fn\"],\n",
    "        device=assembled_model[\"device\"],\n",
    "        epochs=hyperparameters[\"epochs\"],\n",
    "        steps_per_epoch=hyperparameters[\"steps_per_epoch\"],\n",
    "        val_per_epoch=hyperparameters[\"val_per_epoch\"],\n",
    "        save_dir=hyperparameters[\"save_dir\"],\n",
    "        write_val_per_feature=True,\n",
    "        data_range=1,\n",
    "        uses_11_normalization=False,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\")\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now for some actually useful hyperparameters\n",
    "-> to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown /s /t 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
