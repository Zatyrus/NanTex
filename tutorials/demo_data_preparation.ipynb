{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6b5625",
   "metadata": {},
   "source": [
    "## Welcome to the DEMO on Generating Synthetic Overlays of Nanotextural Structures\n",
    "In this notebook, we will generate synthetic overlays of nanotextural structures using the NanTex library. We will prepare training, validation, and testing datasets by overlaying multiple features with various augmentations.\n",
    "\n",
    "### Requirements\n",
    "- Basic knowledge of Python\n",
    "- Python 3.11 or higher\n",
    "- Poetry\n",
    "\n",
    "We assume you followed the installation instructions in the README.md file. If you haven't, please do so **before** proceeding.\n",
    "\n",
    "\n",
    "### Estimated Runtime\n",
    "This notebook should take approximately 20-60 minutes to run, depending on your system's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a39f7",
   "metadata": {},
   "source": [
    "## Part 0: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c3794",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Using your favorite web browser, download the demo dataset from Zenodo [here](https://doi.org/10.5281/zenodo.17120603). The dataset is a compressed file named `NanTex SRM Dataset — SMLM I (ShareLoc).rar`. After downloading, decompress the file to a directory of your choice. You should see nine (9) folders named `$FEATURE$_$USE$` (e.g. *ACT_train*) containing microscopy images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008f31c",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d15089",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## NanTex modules\n",
    "from nantex.data_preparation import Tekhne\n",
    "from nantex.util import pltStyler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c60e2e",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a51cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path setup\n",
    "\n",
    "# select demo data path\n",
    "path_to_demo_data = \"path/to/NanTex SRM Dataset — SMLM I (ShareLoc)\"\n",
    "\n",
    "# select output path\n",
    "path_to_output = \"path/to/output/folder\"\n",
    "\n",
    "# create output folders\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(path_to_output, name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4356e1f",
   "metadata": {},
   "source": [
    "## Part I: Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22fd7a0",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEMO CASE - Training data preparation\n",
    "data_to_generate = \"train\"  # options are 'train', 'val', 'test\n",
    "\n",
    "# data import paths\n",
    "root_feature_1: str = os.path.join(path_to_demo_data, f\"MIC_{data_to_generate}\")\n",
    "root_feature_2: str = os.path.join(path_to_demo_data, f\"LNP_{data_to_generate}\")\n",
    "root_feature_3: str = os.path.join(path_to_demo_data, f\"ACT_{data_to_generate}\")\n",
    "\n",
    "# outpath for prepared data\n",
    "## you are going to use the same routine to prepare data for training, validation, and testing\n",
    "data_path_out = os.path.join(\n",
    "    path_to_output, data_to_generate\n",
    ")  # <- we are gonna start with training data\n",
    "\n",
    "# grab data\n",
    "root_features: list[str] = [root_feature_1, root_feature_2, root_feature_3]\n",
    "\n",
    "# get list of files for each feature\n",
    "root_features = {path: glob(f\"{path}/*.png\") for path in root_features}\n",
    "\n",
    "# choose two (2) images per feature at random for DEMO purposes too cut time\n",
    "if data_to_generate == \"train\":\n",
    "    root_features = [\n",
    "        np.random.choice(root_features[path], size=2, replace=False).tolist()\n",
    "        for path in root_features\n",
    "    ]\n",
    "else:\n",
    "    root_features = [root_features[path] for path in root_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a9c34",
   "metadata": {},
   "source": [
    "### Configure and Instantiate the Tekhne instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dce009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config = {\n",
    "    \"mode\": \"rotation\",  # we're going to overlay features with rotation\n",
    "    \"multi_core\": True,  # enable multi-core for faster processing\n",
    "    \"augment\": True,  # enable augmented generation\n",
    "    \"patches\": 32,  # 32 patches for patch-based generation\n",
    "    \"patchsize\": (256, 256),  # size of extracted patches\n",
    "    \"imagesize\": (2048, 2048),  # size of full output images\n",
    "    \"dtype_out\": np.float32,  # 32-bit output\n",
    "    \"dtype_in\": np.uint8,  # input data type\n",
    "    \"DEBUG\": True,  # print debug messages\n",
    "    \"disable_auto_standardization\": False,  # disable auto standardization for full-frame generation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure and Initialize Tekhne instance\n",
    "OLGen: Tekhne\n",
    "OLGen = Tekhne.from_glob(*root_features, data_path_out=data_path_out, **tekhne_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c477f3",
   "metadata": {},
   "source": [
    "### Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup augmentation pipeline\n",
    "import albumentations as A\n",
    "\n",
    "# parts\n",
    "parts = [\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.MedianBlur(p=0.3, blur_limit=5),\n",
    "]\n",
    "\n",
    "# compose and assign\n",
    "OLGen.augmentation_pipeline = A.Compose(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08926f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(\n",
    "    num_cpu=12,  # number of cpu cores to use\n",
    "    launch_dashboard=True,\n",
    ")  # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a037ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core()  # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e19a06",
   "metadata": {},
   "source": [
    "## Checkpoint I\n",
    "You should have generated a number of augmented patches extracted from synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig, axs = plt.subplots(1, data.shape[0], figsize=(data.shape[0] * 5, 5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap=\"magma\")\n",
    "    axs[i].set_title(f\"Feature {i + 1}\")\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup\n",
    "OLGen:Tekhne\n",
    "OLGen = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acd7e1",
   "metadata": {},
   "source": [
    "## Part II: Validation Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822fe5c",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a394bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEMO CASE - Training data preparation\n",
    "data_to_generate = \"val\"  # options are 'train', 'val', 'test\n",
    "\n",
    "# data import paths\n",
    "root_feature_1: str = os.path.join(path_to_demo_data, f\"MIC_{data_to_generate}\")\n",
    "root_feature_2: str = os.path.join(path_to_demo_data, f\"LNP_{data_to_generate}\")\n",
    "root_feature_3: str = os.path.join(path_to_demo_data, f\"ACT_{data_to_generate}\")\n",
    "\n",
    "# outpath for prepared data\n",
    "## you are going to use the same routine to prepare data for training, validation, and testing\n",
    "data_path_out = os.path.join(\n",
    "    path_to_output, data_to_generate\n",
    ")  # <- we are gonna start with training data\n",
    "\n",
    "# grab data\n",
    "root_features: list[str] = [root_feature_1, root_feature_2, root_feature_3]\n",
    "\n",
    "# get list of files for each feature\n",
    "root_features = {path: glob(f\"{path}/*.png\") for path in root_features}\n",
    "\n",
    "# choose two (2) images per feature at random for DEMO purposes too cut time\n",
    "if data_to_generate == \"train\":\n",
    "    root_features = [\n",
    "        np.random.choice(root_features[path], size=2, replace=False).tolist()\n",
    "        for path in root_features\n",
    "    ]\n",
    "else:\n",
    "    root_features = [root_features[path] for path in root_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ab096",
   "metadata": {},
   "source": [
    "### Configure and Instantiate the Tekhne instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config = {\n",
    "    \"mode\": \"rotation\",  # we're going to overlay features with rotation\n",
    "    \"multi_core\": True,  # enable multi-core for faster processing\n",
    "    \"augment\": True,  # enable augmented generation\n",
    "    \"patches\": 8,  # 8 patches for patch-based generation\n",
    "    \"patchsize\": (256, 256),  # size of extracted patches\n",
    "    \"imagesize\": (2048, 2048),  # size of full output images\n",
    "    \"dtype_out\": np.float32,  # 32-bit output\n",
    "    \"dtype_in\": np.uint8,  # input data type\n",
    "    \"DEBUG\": True,  # print debug messages\n",
    "    \"disable_auto_standardization\": False,  # disable auto standardization for full-frame generation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e690d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure and Initialize Tekhne instance\n",
    "OLGen: Tekhne\n",
    "OLGen = Tekhne.from_glob(*root_features, data_path_out=data_path_out, **tekhne_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea91c9c",
   "metadata": {},
   "source": [
    "### Generate Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup augmentation pipeline\n",
    "import albumentations as A\n",
    "\n",
    "# parts\n",
    "parts = [\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.MedianBlur(p=0.3, blur_limit=5),\n",
    "]\n",
    "\n",
    "# compose and assign\n",
    "OLGen.augmentation_pipeline = A.Compose(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(\n",
    "    num_cpu=12,  # number of cpu cores to use\n",
    "    launch_dashboard=True,\n",
    ")  # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91623ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bec242",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core()  # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01eb591",
   "metadata": {},
   "source": [
    "## Checkpoint II\n",
    "You should have generated a number of augmented patches extracted from synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig, axs = plt.subplots(1, data.shape[0], figsize=(data.shape[0] * 5, 5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap=\"magma\")\n",
    "    axs[i].set_title(f\"Feature {i + 1}\")\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup\n",
    "OLGen:Tekhne\n",
    "OLGen = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47a11e",
   "metadata": {},
   "source": [
    "## Part III: Generation of Full-Frame Synthetic Overlays for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config.update(\n",
    "    {\n",
    "        \"mode\": \"rotation\",  # we're going to overlay features with rotation\n",
    "        \"multi_core\": True,  # enable multi-core for faster processing\n",
    "        \"patches\": 0,  # no patches, full-frame generation\n",
    "        \"imagesize\": (2048, 2048),  # size of full output images\n",
    "        \"dtype_out\": np.uint16,  # 16-bit output\n",
    "        \"DEBUG\": True,  # print debug messages\n",
    "        \"disable_auto_standardization\": True,  # disable auto standardization for full-frame generation\n",
    "    }\n",
    ")\n",
    "OLGen.configure(**tekhne_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(\n",
    "    num_cpu=12,  # number of cpu cores to use\n",
    "    launch_dashboard=True,\n",
    ")  # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96710",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9da8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core()  # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99949e",
   "metadata": {},
   "source": [
    "## Checkpoint III\n",
    "You should have generated a number of synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ce3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig, axs = plt.subplots(1, data.shape[0], figsize=(data.shape[0] * 5, 5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap=\"magma\")\n",
    "    axs[i].set_title(f\"Feature {i + 1}\")\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup\n",
    "OLGen:Tekhne\n",
    "OLGen = None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
