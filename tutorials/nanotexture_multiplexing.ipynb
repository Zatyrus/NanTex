{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f34c62",
   "metadata": {},
   "source": [
    "## Welcome to the Tutorial on Multiplexing Nanotextural Structures with Oneiros\n",
    "In this notebook, we will learn how to use `Oneiros`, a part of the `NanTex` library, to generate multiplexed nanotextural structures from single-channel input data.\n",
    "\n",
    "### Requirements\n",
    "- Basic knowledge of Python\n",
    "- Python 3.11 or higher\n",
    "- Poetry\n",
    "\n",
    "We assume you followed the installation instructions in the README.md file. If you haven't, please do so **before** proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e056b1",
   "metadata": {},
   "source": [
    "## Part 0: Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee2acb",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "from nantex.data_postprocessing.oneiros import Oneiros\n",
    "from nantex.util import pyDialogue as pyD\n",
    "from nantex.util import pltStyler\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33996397",
   "metadata": {},
   "source": [
    "### Overview\n",
    "``` Python\n",
    "# Dreamer\n",
    "# Dreamer = Oneiros(num_features = 3,               # Number of features in the dataset\n",
    "#                   DEBUG=True,                     # Debug mode <- leave on for the first run\n",
    "#                   data_paths_in = None,           # Path to the input data <- in MS Windows, a \"None\" will trigger a file dialog\n",
    "#                   data_path_out = None,           # Path to the output data <- in MS Windows, a \"None\" will trigger a file dialog when you need to save the data\n",
    "#                   mode = 'has_ground_truth')      # Mode of the data processing <- choose dependent on the data you are about to load in\n",
    "\n",
    "\n",
    "# Dreamer WINODWS\n",
    "# -> Dreamer.from_explorer() - this function will call the file explorer dialog to choose the input and output files\n",
    "\n",
    "## There are two convenience functions that we will use in this notebook:\n",
    "# - Dreamer.with_ground_truth() - this function will call \"from_exploer\" with the mode set to \"has_ground_truth\"\n",
    "# - Dreamer.without_ground_truth() - this function will call \"from_exploer\" with the mode set to \"no_ground_truth\"\n",
    "\n",
    "# You need to provide the number of present features and if you want to run it in DEBUG morde or not.\n",
    "# In windows, you can conveniently choose multiple files using the file explorere dialog. \n",
    "\n",
    "# Dreamer LINUX\n",
    "# -> Dreamer.from_glob() - this function will take a number of paths or glob patterns as input and load the data from the files\n",
    "# Dreamer.from_glob(*['path/to/file1', 'path/to/file2', 'path/to/file3']) - this will load the data from the files\n",
    "# You sill need to provide the number of present features and if you want to run it in DEBUG morde or not.\n",
    "```\n",
    "\n",
    "### Data\n",
    "Oneiros can read both .npy and image (png, jpeg, jpg) files. If you want to call the Dreamer with ground truth, you need to provide the data as npy files. If you want to call the Dreamer without ground truth, you can provide the data as images. The npy should have the following shape (number_of_features + 1, y_size, x_size). The shape will match if you use the other packages provided within the NanTex project.\n",
    "\n",
    "### Metaparameters\n",
    "#### We will use the following metaparameters to run the Dreamer.\n",
    "``` Json\n",
    "\"feature_static_threshodls\" : {     # Static thresholds for each feature\n",
    "    \"feature_0\": 0.1,               # Threshold for feature 0\n",
    "    \"feature_1\": 0.1,               # Threshold for feature 1\n",
    "    \"feature_2\": 0.1                # Threshold for feature 2 <- if you have more features, add them here\n",
    "    },\n",
    "\"dynamic_thresholds\": {             # Dynamic thresholds for each feature <- generates histogram and determins the main population of pixel values. \n",
    "                                    # For SMLM this usually is the background and some noise. Be careful using this with images that have a lot of signal.\n",
    "    \"auto_calculate\": True,         # Automatically calculate dynamic thresholds using multiples of the standard deviation\n",
    "    \"upper\": 3,                     # Upper threshold for dynamic threshold calculation <- hist argmax + 3 bins\n",
    "    \"lower\": -2,                    # Lower threshold for dynamic threshold calculation <- hist argmax - 2 bins\n",
    "    \"std_factor\": 2                 # Factor to multiply the standard deviation by < hist argmax +- std_factor * std\n",
    "    },\n",
    "\"patch_size\": (256, 256),           # Size of the patches to be extracted from the images\n",
    "\"dream_memory_shape\" : None,        # Shape of the memory array for the DREAM algorithm <- will be autmatically populated\n",
    "\"patch_array_shape\": None,          # Shape of the patch array <- will be automatically populated\n",
    "\"standardize\": True,                # Standardize the patches\n",
    "\"normalize\": False,                 # Normalize the patches <- not recommended\n",
    "\"tensortype\": torch.float32,        # Type of tensor to be used\n",
    "\"out_type\": np.uint8,               # Determine the type of the output tensor <- usually np.uint8\n",
    "\"weights_only\": True,               # DEBUG parameter when loading a state_dict (torch) <- leave as it\n",
    "\"cast_all_to_img\": True,            # Cast all tensors to images will normalize the output and cast it to the maximum range of the output type\n",
    "\"append_original_features\": True,   # Append the original features to the output tensor <- for your convenience when exporting\n",
    "\"append_original_overlays\": True,   # Append the original overlays to the output tensor\n",
    "\"append_dream_overlays\": True,      # Append the dream overlays to the output tensor\n",
    "\"apply_static_thresholds\": True,    # Apply the static thresholds to dream features \n",
    "\"apply_dynamic_thresholds\": True    # Apply the dynamic thresholds to dream features\n",
    "```\n",
    "\n",
    "#### The metaparameters are stored in a dictionary and can be accessed and changed using the following code:\n",
    "``` Python\n",
    "# Access the metaparameters\n",
    "metaparameters = Dreamer.metaparameters\n",
    "\n",
    "# Change the metaparameters\n",
    "metaparameters['patch_size'] = (256, 256)\n",
    "\n",
    "# Update the metaparameters\n",
    "new_metaparameters = {\n",
    "    'patch_size': (256, 256),\n",
    "    'some_other_metaparameter': 'some_value'                    \n",
    "                     }\n",
    "Dreamer.metaparameters.update(new_metaparameters)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d7d68",
   "metadata": {},
   "source": [
    "## Part 1: Multiplexing Data with Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c6195",
   "metadata": {},
   "source": [
    "### UNIX: Select Data Files and Instantiate Oneiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select filepaths\n",
    "path_to_data_directory: str = \"path/to/your/data\"\n",
    "paths: list = glob(path_to_data_directory + \"/*.npy\")\n",
    "paths = np.random.choice(paths, size=10, replace=False).tolist() # Select 10 random files for demonstration\n",
    "\n",
    "# Select Pre-Trained Model State Dict\n",
    "path_to_pretrained_model_state_dict: str = \"path/to/your/pretrained/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065765dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dreamer for LINUX\n",
    "Dreamer = Oneiros.from_glob(\n",
    "    *paths, num_features=3, num_channels_out=3, DEBUG=True, VERBOSE = True, FREEMEMORY = False, mode=\"has_ground_truth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa452601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change patchsize\n",
    "Dreamer.metadata[\"patch_size\"] = (256, 256)\n",
    "Dreamer.metadata[\"normalize\"] = False\n",
    "Dreamer.metadata[\"standardize\"] = True\n",
    "\n",
    "pprint(Dreamer.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea656c1",
   "metadata": {},
   "source": [
    "### UNIX: Multiplexing Data with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59755805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "Dreamer.jumpstart_model(path_to_pretrained_model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d85b1",
   "metadata": {},
   "source": [
    "If you want to load in more data without reinitializing the model, run:\n",
    "\n",
    "``` Python\n",
    "Dreamer.load_new_data_linux(\"path/to/new/data_1.npy\", \"path/to/new/data_2.npy\", ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dreamer.dream()  # <- this will start the data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f77629",
   "metadata": {},
   "source": [
    "### UNIX: Checkpoint I - Multiplexing Data with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de240e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first dream\n",
    "\n",
    "# stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "Dreamer.visualize(\n",
    "    dream_no=5,  # <- dream number to visualize\n",
    "    cmap=\"inferno\",  # <- colormap to use, defaults to 'gray\n",
    "    ticks=False,  # <- on/off ticks\n",
    "    return_fig_axs=False,\n",
    ")  # <- return fig and axs objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b5bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export your results\n",
    "# npy will export each dream to a 4D tensor\n",
    "# png will export each dream to a folder of pngs\n",
    "\n",
    "Dreamer.export(\n",
    "    out_type=\"png\",  # <- output type, choose from 'png' or 'npy' or implement your own\n",
    "    outpath=\".\",\n",
    ")  # <- output path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e681c",
   "metadata": {},
   "source": [
    "### WINDOWS: Load Data with Ground Truth via File Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Pre-Trained Model State Dict\n",
    "path_to_pretrained_model_state_dict: str = \"path/to/your/pretrained/model_state_dict.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61789475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dreamer with random selection of data with ground truth\n",
    "Dreamer = Oneiros.random_selection_with_ground_truth(\n",
    "    num_selection=10, num_features=3, num_channels_out=3, DEBUG=True, VERBOSE = True, FREEMEMORY = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change patchsize\n",
    "Dreamer.metadata[\"patch_size\"] = (256, 256)\n",
    "Dreamer.metadata[\"normalize\"] = False\n",
    "Dreamer.metadata[\"standardize\"] = True\n",
    "\n",
    "pprint(Dreamer.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ca3c3",
   "metadata": {},
   "source": [
    "If you want to run the entire selected data without rabdom selection run:\n",
    "``` Python\n",
    "Dreamer = Oneiros.with_ground_truth(num_selection=5, num_features=3, num_channels_out=3, DEBUG=True, VERBOSE = True, FREEMEMORY = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66535bf",
   "metadata": {},
   "source": [
    "### WINDOWS: Multiplexing Data with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickstart model\n",
    "# Just choose the torch checkpoint file and the model will be loaded\n",
    "Dreamer.jumpstart_model(path_to_pretrained_model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00f567",
   "metadata": {},
   "source": [
    "Id you want to load new data without reloading the model, run:\n",
    "``` Python\n",
    "Dreamer.load_new_data_windows()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1efe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dreamer.dream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada528b",
   "metadata": {},
   "source": [
    "### WINDOWS: Checkpoint I - Multiplexing Data with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first dream\n",
    "\n",
    "# stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "Dreamer.visualize(\n",
    "    dream_no=0,  # <- dream number to visualize\n",
    "    cmap=\"inferno\",  # <- colormap to use, defaults to 'gray\n",
    "    ticks=False,  # <- on/off ticks\n",
    "    return_fig_axs=False,\n",
    ")  # <- return fig and axs objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the results\n",
    "Dreamer.export(\n",
    "    out_type=\"single_npy\"\n",
    ")  # png <- image, npy <- numpy array, if you want more, you need to implement it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b91c0",
   "metadata": {},
   "source": [
    "## Part II: Custom Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play with the static thresholds to delete background noise\n",
    "Dreamer.metadata[\"feature_static_thresholds\"].update(\n",
    "    {\n",
    "        \"feature_0\": 0.0,\n",
    "        \"feature_1\": 0.0,\n",
    "        \"feature_2\": 0.0,\n",
    "    }\n",
    ")\n",
    "# Play with the dynamic thresholds to  delete structural noise\n",
    "Dreamer.metadata[\"dynamic_thresholds\"].update(\n",
    "    {\"auto_calculate\": True, \"upper\": 3, \"lower\": -2, \"std_factor\": 3}\n",
    ")\n",
    "\n",
    "\n",
    "# Play with the dreamer parameters\n",
    "Dreamer.metadata[\"apply_dynamic_thresholds\"] = False\n",
    "Dreamer.metadata[\"apply_static_thresholds\"] = False\n",
    "\n",
    "# choose what extras to export\n",
    "Dreamer.metadata[\"append_dream_overlays\"] = True\n",
    "Dreamer.metadata[\"append_original_overlays\"] = True\n",
    "Dreamer.metadata[\"append_original_features\"] = True\n",
    "\n",
    "Dreamer.metadata[\"cast_all_to_img\"] = (\n",
    "    True  # if you dont want to export straight to image\n",
    ")\n",
    "\n",
    "# however, you have to re-run the post-processing\n",
    "Dreamer.__post_process_data__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f78939",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot and vsualize the results\n",
    "pltStyler().enforce_stylesheet()\n",
    "Dreamer.visualize(dream_no=0, return_fig_axs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the results\n",
    "Dreamer.export(\n",
    "    out_type=\"png\"\n",
    ")  # png <- image, npy <- numpy array, if you want m0re, you need to implement it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d5630",
   "metadata": {},
   "source": [
    "## Without Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dreamer\n",
    "Dreamer = Oneiros.without_ground_truth(num_features=2, num_channels_out=2, DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dreamer.jumpstart_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dreamer.load_new_data_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c96a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dreamer.dream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first dream\n",
    "pltStyler().enforce_stylesheet()\n",
    "Dreamer.visualize(0, return_fig_axs=False, cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the results\n",
    "Dreamer.export(\n",
    "    out_type=\"png\"\n",
    ")  # png <- image, npy <- numpy array, if you want mire, you need to implement it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex_Demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
