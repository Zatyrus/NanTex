{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5280a20",
   "metadata": {},
   "source": [
    "## Welcome to the Tutorial on Generating Synthetic Overlays of Nanotextural Structures\n",
    "In this notebook, we will learn how to use `Tekhne`, a part of the `NanTex` library, to generate synthetic overlays of nanotextural structures. The goal is to generate datasets that can be used to train, validate and test the deep learning models developed in the `NanTex` library.\n",
    "\n",
    "### Requirements\n",
    "- Basic knowledge of Python\n",
    "- Python 3.11 or higher\n",
    "- Poetry\n",
    "\n",
    "We assume you followed the installation instructions in the README.md file. If you haven't, please do so **before** proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6852d",
   "metadata": {},
   "source": [
    "**Heads-up** \\\\\\ Some of our modules contain convenience functions that interface with the Windows file system. If you are using a different operating system, we advise you to follow the \"UNIX\" part of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4213e2",
   "metadata": {},
   "source": [
    "## Part 0: Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98d6e4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## NanTex modules\n",
    "from nantex.data_preparation import Tekhne\n",
    "from nantex.util import pltStyler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2988ea",
   "metadata": {},
   "source": [
    "### DEMO DATA\n",
    "Using your favorite web browser, download the demo dataset from Zenodo [here](https://doi.org/10.5281/zenodo.17120603). The dataset is a compressed file named `NanTex SRM Dataset â€” SMLM I (ShareLoc).rar`. After downloading, decompress the file to a directory of your choice. You should see nine (9) folders named `$FEATURE$_$USE$` (e.g. *ACT_train*) containing microscopy images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c980a",
   "metadata": {},
   "source": [
    "## Part I: Configure and Instantiate the Tekhne instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c87100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the generator\n",
    "tekhne_config = {\n",
    "    \"mode\": 'overlay',          # what output to generate, 'overlay' or 'rotation'\n",
    "    \"multi_core\": False,        # use multiple cores, powered by ray\n",
    "    \"augment\": False,           # apply data augmentation\n",
    "    \"patches\": 32,              # number of patches to extract from each input file\n",
    "    \"patchsize\": (256,256),     # size of extracted patches\n",
    "    \"imagesize\": (2048,2048),   # size of full output images\n",
    "    \"dtype_out\": np.float32,    # output data type\n",
    "    \"dtype_in\": np.uint8,       # input data type\n",
    "    \"DEBUG\": True               # print debug messages\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc025df3",
   "metadata": {},
   "source": [
    "### UNIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2abbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Metaparameters and data paths\n",
    "\n",
    "# data import paths\n",
    "root_feature_1:str = 'path/to/your/first/feature'\n",
    "root_feature_2:str = 'path/to/your/second/feature'\n",
    "root_feature_3:str = 'path/to/your/third/feature'\n",
    "... # add more features when needed\n",
    "\n",
    "# outpath for prepared data\n",
    "data_path_out = \"path/to/your/output/directory\"\n",
    "\n",
    "# grab data\n",
    "root_features:list[str] = [root_feature_1, \n",
    "                           root_feature_2, \n",
    "                           root_feature_3] # add more features when needed\n",
    "# get list of files for each feature\n",
    "root_features = [glob(f\"{root}/*.npy\") for root in root_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure and Initialize Tekhne instance\n",
    "OLGen:Tekhne\n",
    "OLGen = Tekhne.from_glob(*root_features, data_path_out = data_path_out, **tekhne_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c0619",
   "metadata": {},
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106578e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup\n",
    "OLGen: Tekhne\n",
    "OLGen = Tekhne.from_explorer(**tekhne_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672ae69",
   "metadata": {},
   "source": [
    "### Checkpoint I\n",
    "By now you should have a Tekhne instance configured. Let's take a look at the metadata of the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c24c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLGen.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f6778",
   "metadata": {},
   "source": [
    "## Tutorial Part II: Single Core Generation of Full-Frame Synthetic Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config.update({\n",
    "    \"mode\": 'overlay',          # we're going to just overlay features\n",
    "    \"multi_core\": False,        # disable multi-core for simplicity\n",
    "    \"patches\": 0,               # no patches, full-frame generation\n",
    "    \"imagesize\": (2048,2048),   # size of full output images\n",
    "    \"dtype_out\": np.uint16,     # 16-bit output\n",
    "    \"DEBUG\": True,              # print debug messages\n",
    "    \"disable_auto_standardization\": True  # disable auto standardization for full-frame generation\n",
    "})\n",
    "OLGen.configure(**tekhne_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af077852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (single core)\n",
    "OLGen.generate_overlay()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671fad7",
   "metadata": {},
   "source": [
    "### Checkpoint II\n",
    "You should have generated a number of synthetic overlays. Let's take a look at your data directory and one of the generated overlays.\n",
    "\n",
    "**Before we proceed - try the following:**\n",
    "* try changing the mode to \"rotation\"\n",
    "* try lowering the imagesize\n",
    "* try increasing the imagesize (zero-padding will be applied if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d734616",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f826cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(data_files[0])\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig,axs = plt.subplots(1,data.shape[0], figsize=(data.shape[0] * 5,5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap='magma')\n",
    "    axs[i].set_title(f\"Feature {i+1}\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup the files in the output directory\n",
    "import shutil, os\n",
    "\n",
    "# get the filecount in the output directory\n",
    "data_files_in = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "\n",
    "# remove all files in the output directory\n",
    "shutil.rmtree(OLGen.data_path_out)\n",
    "os.makedirs(OLGen.data_path_out, exist_ok=True)\n",
    "\n",
    "# check files left\n",
    "data_files_out = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Cleaned up {len(data_files_in) - len(data_files_out)} files.\")\n",
    "\n",
    "# restore input data from backup\n",
    "OLGen.restore_input_data_from_backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6373527",
   "metadata": {},
   "source": [
    "## Part III: Multi-Core Generation of Full-Frame Synthetic Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config.update({\n",
    "    \"mode\": 'rotation',         # we're going to overlay features with rotation\n",
    "    \"multi_core\": True,         # enable multi-core for faster processing\n",
    "    \"patches\": 0,               # no patches, full-frame generation\n",
    "    \"imagesize\": (2048,2048),   # size of full output images\n",
    "    \"dtype_out\": np.uint16,     # 16-bit output\n",
    "    \"DEBUG\": True,              # print debug messages\n",
    "    \"disable_auto_standardization\": True  # disable auto standardization for full-frame generation\n",
    "})\n",
    "OLGen.configure(**tekhne_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586876aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(num_cpu=12,               # number of cpu cores to use\n",
    "                       launch_dashboard=True)   # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fec2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core() # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc210f7",
   "metadata": {},
   "source": [
    "### Checkpoint III\n",
    "You should have generated a number of synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3399f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2df780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig,axs = plt.subplots(1,data.shape[0], figsize=(data.shape[0] * 5,5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap='magma')\n",
    "    axs[i].set_title(f\"Feature {i+1}\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98469411",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup the files in the output directory\n",
    "import shutil, os\n",
    "\n",
    "# get the filecount in the output directory\n",
    "data_files_in = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "\n",
    "# remove all files in the output directory\n",
    "shutil.rmtree(OLGen.data_path_out)\n",
    "os.makedirs(OLGen.data_path_out, exist_ok=True)\n",
    "\n",
    "# check files left\n",
    "data_files_out = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Cleaned up {len(data_files_in) - len(data_files_out)} files.\")\n",
    "\n",
    "# restore input data from backup\n",
    "OLGen.restore_input_data_from_backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8ea0e",
   "metadata": {},
   "source": [
    "## Part IV: Patched Multi-Core Generation of Synthetic Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config.update({\n",
    "    \"mode\": 'rotation',         # we're going to overlay features with rotation\n",
    "    \"multi_core\": True,         # enable multi-core for faster processing\n",
    "    \"patches\": 32,              # 32 patches for patch-based generation\n",
    "    \"patchsize\": (256,256),     # size of extracted patches\n",
    "    \"imagesize\": (2048,2048),   # size of full output images\n",
    "    \"dtype_out\": np.float32,    # 32-bit output\n",
    "    \"dtype_in\": np.uint8,       # input data type\n",
    "    \"DEBUG\": True,              # print debug messages\n",
    "    \"disable_auto_standardization\": False  # disable auto standardization for full-frame generation\n",
    "})\n",
    "OLGen.configure(**tekhne_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(num_cpu=16,               # number of cpu cores to use\n",
    "                       launch_dashboard=True)    # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9abe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core() # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b4ac4",
   "metadata": {},
   "source": [
    "## Checkpoint IV\n",
    "You should have generated a number of synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig,axs = plt.subplots(1,data.shape[0], figsize=(data.shape[0] * 5,5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap='magma')\n",
    "    axs[i].set_title(f\"Feature {i+1}\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup the files in the output directory\n",
    "import shutil, os\n",
    "\n",
    "# get the filecount in the output directory\n",
    "data_files_in = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "\n",
    "# remove all files in the output directory\n",
    "shutil.rmtree(OLGen.data_path_out)\n",
    "os.makedirs(OLGen.data_path_out, exist_ok=True)\n",
    "\n",
    "# check files left\n",
    "data_files_out = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Cleaned up {len(data_files_in) - len(data_files_out)} files.\")\n",
    "\n",
    "# restore input data from backup\n",
    "OLGen.restore_input_data_from_backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f031b26",
   "metadata": {},
   "source": [
    "## Part V: Augmented Patched Multi-Core Generation of Synthetic Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure for Single Core Generation of Synthetic Overlays\n",
    "tekhne_config.update({\n",
    "    \"mode\": 'rotation',         # we're going to overlay features with rotation\n",
    "    \"multi_core\": True,         # enable multi-core for faster processing\n",
    "    \"augment\": True,            # enable augmented generation\n",
    "    \"patches\": 8,               # 32 patches for patch-based generation\n",
    "    \"patchsize\": (256,256),     # size of extracted patches\n",
    "    \"imagesize\": (2048,2048),   # size of full output images\n",
    "    \"dtype_out\": np.float32,    # 32-bit output\n",
    "    \"dtype_in\": np.uint8,       # input data type\n",
    "    \"DEBUG\": True,              # print debug messages\n",
    "    \"disable_auto_standardization\": False  # disable auto standardization for full-frame generation\n",
    "})\n",
    "OLGen.configure(**tekhne_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup augmentation pipeline\n",
    "import albumentations as A\n",
    "\n",
    "# parts\n",
    "parts = [A.VerticalFlip(p=0.5), A.HorizontalFlip(p=0.5), A.MedianBlur(p=0.3, blur_limit=5)]\n",
    "\n",
    "# compose and assign\n",
    "OLGen.augmentation_pipeline = A.Compose(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup multi core (multi core)\n",
    "OLGen.setup_multi_core(num_cpu=12,              # number of cpu cores to use\n",
    "                       launch_dashboard=True)   # launch the ray dashboard <- default is True\n",
    "\n",
    "## The runtime instance is accessible via:\n",
    "OLGen._ray_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check how many combinations we can generate\n",
    "OLGen.estimate_number_of_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the overlay (multi core)\n",
    "OLGen.generate_overlay()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleanup (multi core)\n",
    "OLGen.shutdown_multi_core() # shutdown the ray cluster. cleanup the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ca039",
   "metadata": {},
   "source": [
    "## Checkpoint V\n",
    "You should have generated a number of augmented patches extracted from synthetic rotational overlays. Let's take a look at your data directory and one of the generated overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets find your data\n",
    "data_files = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Found {len(data_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f98fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at one of the generated overlays\n",
    "data = np.load(np.random.choice(data_files))\n",
    "\n",
    "# apply stylesheet\n",
    "pltStyler().enforce_stylesheet()\n",
    "\n",
    "# plot overlays\n",
    "fig,axs = plt.subplots(1,data.shape[0], figsize=(data.shape[0] * 5,5))\n",
    "for i in range(data.shape[0]):\n",
    "    axs[i].imshow(data[i], cmap='magma')\n",
    "    axs[i].set_title(f\"Feature {i+1}\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "axs[-1].set_title(\"Overlay\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7424da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup the files in the output directory\n",
    "import shutil, os\n",
    "\n",
    "# get the filecount in the output directory\n",
    "data_files_in = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "\n",
    "# remove all files in the output directory\n",
    "shutil.rmtree(OLGen.data_path_out)\n",
    "os.makedirs(OLGen.data_path_out, exist_ok=True)\n",
    "\n",
    "# check files left\n",
    "data_files_out = glob(f\"{OLGen.data_path_out}/*.npy\")\n",
    "print(f\"Cleaned up {len(data_files_in) - len(data_files_out)} files.\")\n",
    "\n",
    "# restore input data from backup\n",
    "OLGen.restore_input_data_from_backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd7442",
   "metadata": {},
   "source": [
    "## Part VI: EXTRA - A More Sophisticated Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cefaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import albumentations as A\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Pipelines\n",
    "\n",
    "# Define types\n",
    "train_transform_schedule: List[A.ImageOnlyTransform]\n",
    "val_transform_schedule: List[A.ImageOnlyTransform]\n",
    "test_transform_schedule: List[A.ImageOnlyTransform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train augmentation pipelines\n",
    "train_transform_schedule = [\n",
    "    A.RandomCrop(\n",
    "        256,\n",
    "        256,\n",
    "        p=1,  # <- always apply\n",
    "    ),  # Randomly crop the image <- choose a random crop of 256x256\n",
    "    A.HorizontalFlip(p=0.5),  # Randomly flip the image horizontally (50% of the time)\n",
    "    A.VerticalFlip(p=0.5),  # Randomly flip the image vertically (50% of the time)\n",
    "    # Apply median blur with a 30% probability, kernes size is 5 <- play with the size to enhance the effect.\n",
    "    # ADJUST IF, SHOULD OPENCV THROW A WEIRD ERROR.\n",
    "    # (https://stackoverflow.com/questions/13193207/unsupported-format-or-combination-of-formats-when-using-cvreduce-method-in-ope)\n",
    "    A.MedianBlur(p=0.3, blur_limit=3),\n",
    "]\n",
    "\n",
    "# building blocks for various applications in microscopy\n",
    "# building blocks = [A.GaussNoise(p=0.5),\n",
    "#                    A.MedianBlur(p=0.7, blur_limit=(3, 5)),\n",
    "#                    A.RandomBrightnessContrast(p=0.3, brightness_limit=0.2, contrast_limit=0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acaf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation augmentation pipelines\n",
    "# it is important to have the same transformations for validation\n",
    "val_transform_schedule = train_transform_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test augmentation pipelines\n",
    "# note that we do not want to apply blurring or other soft transformations as we assume peak quality for the test set\n",
    "# in training, we use blurring to make the model more robust to noise\n",
    "test_transform_schedule = [\n",
    "    A.RandomCrop(256, 256, p=1),  # p=1 == apply always\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d211eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compose the transformations\n",
    "train_augmentation_pipeline: A.Compose = A.Compose(train_transform_schedule)\n",
    "val_augmentation_pipeline: A.Compose = A.Compose(val_transform_schedule)\n",
    "test_augmentation_pipeline: A.Compose = A.Compose(test_transform_schedule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex_Demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
