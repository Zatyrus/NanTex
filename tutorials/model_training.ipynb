{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0d6989",
   "metadata": {},
   "source": [
    "## Welcome to this tutorial on how to train your own nanotextural demixing model using the `NanTex` library! \n",
    "In this tutorial, we will focus on the second part of the process: constructing and training the network using the `Hypnos` module of the `NanTex` library.\n",
    "\n",
    "### Requirements\n",
    "- Synthetic overlay data generated with the `Tekhne` module of the `NanTex` package (see `tekhne_tutorial.ipynb`)\n",
    "- Tested installation of PyTorch, ideally with GPU support (see `installation_guide.md`)\n",
    "- Tested installation of TensorBoard (see `installation_guide.md`)\n",
    "- `NanTex` package installed (see `installation_guide.md`)\n",
    "- Basic knowledge of Python and Jupyter Notebooks\n",
    "\n",
    "If you haven't completed the first part of the process, please refer to the `tekhne_tutorial.ipynb` notebook to generate synthetic overlay data. This data will be used to train the demixing model in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1cd6b",
   "metadata": {},
   "source": [
    "## Part 0: Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff06b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "# Model (Hypnos)\n",
    "from nantex.deep_learning.dl_building_blocks import train\n",
    "from nantex.deep_learning.dl_model_assembly import (\n",
    "    assembled_model,\n",
    "    hyperparameters,\n",
    ")\n",
    "\n",
    "# Dataloaders (Harmonia)\n",
    "from nantex.batching import Harmonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e97cab",
   "metadata": {},
   "source": [
    "## Part I: Configure and Instantiate Harmonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Config\n",
    "\n",
    "# define and create config directory\n",
    "config_dir = \"../configs/\"\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "# generate boilerplate config file\n",
    "if not os.path.exists(os.path.join(config_dir, \"harmonia_config.json\")):\n",
    "    Harmonia.generate_boilerplate_config_file(config_dir)\n",
    "\n",
    "# show the generated config file\n",
    "with open(os.path.join(config_dir, \"harmonia_config.json\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157ee04",
   "metadata": {},
   "source": [
    "**Heads-up** \\\\\\ Some of our modules contain convenience functions that interface with the Windows file system. If you are using a UNIX based system (Linux, MacOS), you will need to provide the directory paths manually in the configuration files. Please refer to the docstrings of the respective functions for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea882cb",
   "metadata": {},
   "source": [
    "## UNIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c356d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define train and validation directories\n",
    "raw_source: str = \"../path/to/directory/containing/training/olverays/\"\n",
    "val_source: str = \"../path/to/directory/containing/validation/olverays/\"\n",
    "\n",
    "# write to config file\n",
    "with open(os.path.join(config_dir, \"harmonia_config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# update config with new paths\n",
    "config[\"raw_source\"] = raw_source\n",
    "config[\"val_source\"] = val_source\n",
    "\n",
    "# write updated config back to file\n",
    "with open(os.path.join(config_dir, \"harmonia_config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate\n",
    "BatchProvider: Harmonia\n",
    "BatchProvider = Harmonia.from_config(\n",
    "    config_file_path=\"../configs/harmonia_config.json\", datatype=\"npy\", DEBUG=True\n",
    ")\n",
    "\n",
    "# the configuration can also be passed as a dictionary\n",
    "with open(\"../configs/harmonia_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "BatchProvider = Harmonia(config=config, datatype=\"npy\", DEBUG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b28472",
   "metadata": {},
   "source": [
    "## Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b3a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate\n",
    "BatchProvider: Harmonia\n",
    "BatchProvider = Harmonia.from_config(\n",
    "    config_file_path=\"../configs/harmonia_config.json\", datatype=\"npy\", DEBUG=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23910efe",
   "metadata": {},
   "source": [
    "### Checkpoint I: Instantiate the `Harmonia` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check the configuration\n",
    "BatchProvider.pprint_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a56ed",
   "metadata": {},
   "source": [
    "## Part II: Configure CUDA and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b81e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if CUDA is available\n",
    "\n",
    "# set backend flags\n",
    "torch.backends.cudnn.enabled = True  # use CUDNN Cuda Deep Neural Network library\n",
    "torch.backends.cudnn.benchmark = True  # enable benchmarking for optimized performance -> benchmark multiple convolution algorithms and choose the fastest\n",
    "\n",
    "print(\"Checking CUDA availability...\")\n",
    "print(\"  version:\", torch.__version__)\n",
    "print(\"  CUDA available:\", torch.cuda.is_available())\n",
    "print(\"  cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print()\n",
    "print(\"Checking on GPU...\")\n",
    "print(\"  GPU count:\", torch.cuda.device_count())\n",
    "print(\"  Current device:\", torch.cuda.current_device())\n",
    "print(\"  Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print()\n",
    "print(\"cuDNN properties:\")\n",
    "print(\"  Version:\", torch.backends.cudnn.version())\n",
    "print(\"  Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"  Benchmark:\", torch.backends.cudnn.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f71d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define and Check Model Hyperparameters\n",
    "\n",
    "# modify hyperparameters as needed\n",
    "hyperparameters.update(\n",
    "    {\n",
    "        \"epochs\": 32,\n",
    "        \"steps_per_epoch\": 256,\n",
    "        \"val_per_epoch\": 128,\n",
    "    }\n",
    ")\n",
    "\n",
    "# add path to store training logs and model checkpoints\n",
    "save_dir: str = \"../model_checkpoints/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "hyperparameters[\"save_dir\"] = save_dir\n",
    "\n",
    "# check hyperparameters\n",
    "pprint(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8706e9",
   "metadata": {},
   "source": [
    "### Checkpoint II\n",
    "By now you should have:\n",
    "* Data providers\n",
    "* A configured CUDA environment\n",
    "* Custom hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18318627",
   "metadata": {},
   "source": [
    "## Part III: Construct Data Iterators and Conduct Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84245866",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained model if available\n",
    "import os\n",
    "\n",
    "state_dict_path: str = \".../path/to/pretrained/model_state_dict.pth\"\n",
    "if os.path.exists(state_dict_path):\n",
    "    print(f\"Loading pre-trained model from {state_dict_path}...\")\n",
    "    assembled_model[\"model\"].load_state_dict(\n",
    "        torch.load(state_dict_path, weights_only=True)\n",
    "    )\n",
    "    print(\"Pre-trained model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04067456",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Data Iterators\n",
    "train_batcher, validation_batcher = BatchProvider.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Setup Test\n",
    "try:\n",
    "    train(\n",
    "        train_loader=train_batcher,\n",
    "        val_loader=validation_batcher,\n",
    "        net=assembled_model[\"model\"],\n",
    "        activation=assembled_model[\"activation\"],\n",
    "        optimizer=assembled_model[\"optimizer\"],\n",
    "        loss_fn=assembled_model[\"loss_fn\"],\n",
    "        device=assembled_model[\"device\"],\n",
    "        **hyperparameters,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\")\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbc8b6",
   "metadata": {},
   "source": [
    "### Checkpoint III: Model Training\n",
    "Now you are ready to train your model! You can do this by calling the `train` function from the `dl_building_blocks_val_after_epoch` module. This function allows you to specify various parameters for training, including the number of epochs, steps per epoch, validation frequency, and more.\n",
    "\n",
    "The `train` method implements automatic validation after a specified number of epochs, allowing you to monitor the model's performance on a validation dataset during training. This is particularly useful for preventing overfitting and ensuring that the model generalizes well to unseen data.\n",
    "\n",
    "You can find the logs and model checkpoints in the directory specified by the `save_dir` parameter.\n",
    "Per default this is set to `./model_checkpoints/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex_Demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
