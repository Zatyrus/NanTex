{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0d6989",
   "metadata": {},
   "source": [
    "## Welcome to this tutorial on how to train your own nanotextural demixing model using the `NanTex` library! \n",
    "In this tutorial, we will focus on the second part of the process: constructing and training the network using the `Hypnos` module of the `NanTex` library.\n",
    "\n",
    "### Requirements\n",
    "- Synthetic overlay data generated with the `Tekhne` module of the `NanTex` package (see `tekhne_tutorial.ipynb`)\n",
    "- Tested installation of PyTorch, ideally with GPU support (see `installation_guide.md`)\n",
    "- Tested installation of TensorBoard (see `installation_guide.md`)\n",
    "- `NanTex` package installed (see `installation_guide.md`)\n",
    "- Basic knowledge of Python and Jupyter Notebooks\n",
    "\n",
    "If you haven't completed the first part of the process, please refer to the `tekhne_tutorial.ipynb` notebook to generate synthetic overlay data. This data will be used to train the demixing model in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1cd6b",
   "metadata": {},
   "source": [
    "## Part 0: Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff06b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "# Model (Hypnos)\n",
    "from nantex.deep_learning.dl_building_blocks import train\n",
    "from nantex.deep_learning.dl_model_assembly import (\n",
    "    assembled_model,\n",
    "    hyperparameters,\n",
    ")\n",
    "\n",
    "# Dataloaders (Harmonia)\n",
    "from nantex.batching import Harmonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e97cab",
   "metadata": {},
   "source": [
    "## Part I: Configure and Instantiate Harmonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Config\n",
    "\n",
    "# define and create config directory\n",
    "config_dir = '../configs/'\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "# generate boilerplate config file\n",
    "Harmonia.generate_boilerplate_config_file(config_dir)\n",
    "\n",
    "# show the generated config file\n",
    "with open(os.path.join(config_dir, 'harmonia_config.json'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157ee04",
   "metadata": {},
   "source": [
    "**Heads-up** \\\\\\ Some of our modules contain convenience functions that interface with the Windows file system. If you are using a UNIX based system (Linux, MacOS), you will need to provide the directory paths manually in the configuration files. Please refer to the docstrings of the respective functions for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea882cb",
   "metadata": {},
   "source": [
    "## UNIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c356d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define train and validation directories\n",
    "raw_source:str = '../path/to/directory/containing/training/olverays/'\n",
    "val_source:str = '../path/to/directory/containing/validation/olverays/'\n",
    "\n",
    "# write to config file\n",
    "with open(os.path.join(config_dir, 'harmonia_config.json'), 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# update config with new paths\n",
    "config['raw_source'] = raw_source\n",
    "config['val_source'] = val_source\n",
    "\n",
    "# write updated config back to file\n",
    "with open(os.path.join(config_dir, 'harmonia_config.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate\n",
    "BatchProvider:Harmonia\n",
    "BatchProvider = Harmonia.from_config(config_file_path='../configs/harmonia_config.json',\n",
    "                                     datatype='npy',\n",
    "                                     DEBUG=True)\n",
    "\n",
    "# the configuration can also be passed as a dictionary\n",
    "with open('../configs/harmonia_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "BatchProvider = Harmonia(config=config,\n",
    "                         datatype='npy',\n",
    "                         DEBUG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b28472",
   "metadata": {},
   "source": [
    "## Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b3a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate\n",
    "BatchProvider:Harmonia\n",
    "BatchProvider = Harmonia.from_config(config_file_path='../configs/harmonia_config.json',\n",
    "                                     datatype='npy',\n",
    "                                     DEBUG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23910efe",
   "metadata": {},
   "source": [
    "### Checkpoint I: Instantiate the `Harmonia` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check the configuration\n",
    "BatchProvider.pprint_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a56ed",
   "metadata": {},
   "source": [
    "## Part II: Configure CUDA and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b81e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if CUDA is available\n",
    "\n",
    "# set backend flags\n",
    "torch.backends.cudnn.enabled = True  # use CUDNN Cuda Deep Neural Network library\n",
    "torch.backends.cudnn.benchmark = True  # enable benchmarking for optimized performance -> benchmark multiple convolution algorithms and choose the fastest\n",
    "\n",
    "print(\"Checking CUDA availability...\")\n",
    "print(\"  version:\", torch.__version__)\n",
    "print(\"  CUDA available:\", torch.cuda.is_available())\n",
    "print(\"  cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print()\n",
    "print(\"Checking on GPU...\")\n",
    "print(\"  GPU count:\", torch.cuda.device_count())\n",
    "print(\"  Current device:\", torch.cuda.current_device())\n",
    "print(\"  Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print()\n",
    "print(\"cuDNN properties:\")\n",
    "print(\"  Version:\", torch.backends.cudnn.version())\n",
    "print(\"  Enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"  Benchmark:\", torch.backends.cudnn.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f71d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define and Check Model Hyperparameters\n",
    "\n",
    "# modify hyperparameters as needed\n",
    "hyperparameters.update({\n",
    "    \"epiochs\": 10,\n",
    "    \"steps_per_epoch\": 2,\n",
    "    \"val_per_epoch\": 1,\n",
    "})\n",
    "\n",
    "# add path to store training logs and model checkpoints\n",
    "save_dir:str = '../model_checkpoints/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "hyperparameters['save_dir'] = save_dir\n",
    "\n",
    "# check hyperparameters\n",
    "pprint(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8706e9",
   "metadata": {},
   "source": [
    "### Checkpoint II\n",
    "By now you should have:\n",
    "* Data providers\n",
    "* A configured CUDA environment\n",
    "* Custom hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18318627",
   "metadata": {},
   "source": [
    "## Part III: Construct Data Iterators and Conduct Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04067456",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Data Iterators\n",
    "train_batcher, validation_batcher = BatchProvider.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Setup Test\n",
    "try:\n",
    "    train(\n",
    "        train_loader=train_batcher,\n",
    "        val_loader=validation_batcher,\n",
    "        net=assembled_model[\"model\"],\n",
    "        activation=assembled_model[\"activation\"],\n",
    "        optimizer=assembled_model[\"optimizer\"],\n",
    "        loss_fn=assembled_model[\"loss_fn\"],\n",
    "        device=assembled_model[\"device\"],\n",
    "        epochs=hyperparameters[\"epochs\"],\n",
    "        steps_per_epoch=hyperparameters[\"steps_per_epoch\"],\n",
    "        val_per_epoch=hyperparameters[\"val_per_epoch\"],\n",
    "        save_dir=hyperparameters[\"save_dir\"],\n",
    "        write_val_per_feature=True,\n",
    "        data_range=1,\n",
    "        uses_11_normalization=False,\n",
    "        num_channels=2\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\")\n",
    "    print(e)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanTex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
